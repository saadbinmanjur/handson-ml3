{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iSWQLVkcpnN"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNxJVPG9cpnR"
      },
      "source": [
        "This project requires Python 3.7 or above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DeAYjXY4cpnS"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "assert sys.version_info >= (3, 7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBnBxYHecpnT"
      },
      "source": [
        "And TensorFlow ≥ 2.8:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SOEFyWHccpnU"
      },
      "outputs": [],
      "source": [
        "from packaging import version\n",
        "import tensorflow as tf\n",
        "\n",
        "assert version.parse(tf.__version__) >= version.parse(\"2.8.0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NxLpxJ4cpnV"
      },
      "source": [
        "This chapter can be very slow without a GPU, so let's make sure there's one, or else issue a warning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kK52NWA0cpnW",
        "outputId": "15d4effa-d5a9-449a-91e7-c0e6fc079c98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of physical CPUs: 2\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(\"Number of physical CPUs:\", os.cpu_count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne_5XGTEcpnW",
        "outputId": "a00d9bc6-1ac9-4f09-b168-e1d2a179c6bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs: 1\n"
          ]
        }
      ],
      "source": [
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "print(\"Num GPUs:\", len(physical_devices))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Zg52hr2VcpnX"
      },
      "outputs": [],
      "source": [
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No GPU was detected. Neural nets can be very slow without a GPU.\")\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware \"\n",
        "              \"accelerator.\")\n",
        "    if \"kaggle_secrets\" in sys.modules:\n",
        "        print(\"Go to Settings > Accelerator and select GPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6zKf2hs8hdYc"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cevx2zArcpnX"
      },
      "source": [
        "## 8.\n",
        "_Exercise:_ Embedded Reber grammars _were used by Hochreiter and Schmidhuber in [their paper](https://homl.info/93) about LSTMs. They are artificial grammars that produce strings such as \"BPBTSXXVPSEPE.\" Check out Jenny Orr's [nice introduction](https://homl.info/108) to this topic.\n",
        "\n",
        "Choose a particular embedded Reber grammar (such as the one represented on Jenny Orr's page),\n",
        "\n",
        "then train an RNN to identify whether a string respects that grammar or not.\n",
        "\n",
        "You will first need to write a function capable of generating a training batch containing about 50% strings that respect the grammar, and 50% that don't._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHVyYGldcpnX"
      },
      "source": [
        "First we need to build a function that generates strings based on a grammar. The grammar will be represented as a list of possible transitions for each state. A transition specifies the string to output (or a grammar to generate it) and the next state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHXsi1ddcpnX"
      },
      "outputs": [],
      "source": [
        "default_reber_grammar = [\n",
        "    [(\"B\", 1)],           # (state 0) =B=>(state 1)\n",
        "    [(\"T\", 2), (\"P\", 3)], # (state 1) =T=>(state 2) or =P=>(state 3)\n",
        "    [(\"S\", 2), (\"X\", 4)], # (state 2) =S=>(state 2) or =X=>(state 4)\n",
        "    [(\"T\", 3), (\"V\", 5)], # and so on...\n",
        "    [(\"X\", 3), (\"S\", 6)],\n",
        "    [(\"P\", 4), (\"V\", 6)],\n",
        "    [(\"E\", None)]]        # (state 6) =E=>(terminal state)\n",
        "\n",
        "embedded_reber_grammar = [\n",
        "    [(\"B\", 1)],\n",
        "    [(\"T\", 2), (\"P\", 3)],\n",
        "    [(default_reber_grammar, 4)],\n",
        "    [(default_reber_grammar, 5)],\n",
        "    [(\"T\", 6)],\n",
        "    [(\"P\", 6)],\n",
        "    [(\"E\", None)]]\n",
        "\n",
        "def generate_string(grammar):\n",
        "    state = 0\n",
        "    output = []\n",
        "    while state is not None:\n",
        "        index = np.random.randint(len(grammar[state]))\n",
        "        production, state = grammar[state][index]\n",
        "        if isinstance(production, list):\n",
        "            production = generate_string(grammar=production)\n",
        "        output.append(production)\n",
        "    return \"\".join(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKCehpZmcpnY"
      },
      "source": [
        "Let's generate a few strings based on the default Reber grammar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4XCDw-mcpnY",
        "outputId": "83ee086d-2648-409b-c4a7-88aec519fb7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BTXXTTVPXTVPXTTVPSE BPVPSE BTXSE BPVVE BPVVE BTSXSE BPTVPXTTTVVE BPVVE BTXSE BTXXVPSE BPTTTTTTTTVVE BTXSE BPVPSE BTXSE BPTVPSE BTXXTVPSE BPVVE BPVVE BPVVE BPTTVVE BPVVE BPVVE BTXXVVE BTXXVVE BTXXVPXVVE "
          ]
        }
      ],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "for _ in range(25):\n",
        "    print(generate_string(default_reber_grammar), end=\" \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r6437vjcpnY"
      },
      "source": [
        "Looks good. Now let's generate a few strings based on the embedded Reber grammar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FlBhii7cpnY",
        "outputId": "11dee5b1-f7b8-480e-a107-8552ac7dff6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BTBPTTTVPXTVPXTTVPSETE BPBPTVPSEPE BPBPVVEPE BPBPVPXVVEPE BPBTXXTTTTVVEPE BPBPVPSEPE BPBTXXVPSEPE BPBTSSSSSSSXSEPE BTBPVVETE BPBTXXVVEPE BPBTXXVPSEPE BTBTXXVVETE BPBPVVEPE BPBPVVEPE BPBTSXSEPE BPBPVVEPE BPBPTVPSEPE BPBTXXVVEPE BTBPTVPXVVETE BTBPVVETE BTBTSSSSSSSXXVVETE BPBTSSSXXTTTTVPSEPE BTBPTTVVETE BPBTXXTVVEPE BTBTXSETE "
          ]
        }
      ],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "for _ in range(25):\n",
        "    print(generate_string(embedded_reber_grammar), end=\" \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVWWxta7cpnY"
      },
      "source": [
        "Okay, now we need a function to generate strings that do not respect the grammar. We could generate a random string, but the task would be a bit too easy, so instead we will generate a string that respects the grammar, and we will corrupt it by changing just one character:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vPNTIW0cpnY"
      },
      "outputs": [],
      "source": [
        "POSSIBLE_CHARS = \"BEPSTVX\"\n",
        "\n",
        "def generate_corrupted_string(grammar, chars=POSSIBLE_CHARS):\n",
        "    good_string = generate_string(grammar)\n",
        "    index = np.random.randint(len(good_string))\n",
        "    good_char = good_string[index]\n",
        "    bad_char = np.random.choice(sorted(set(chars) - set(good_char)))\n",
        "    return good_string[:index] + bad_char + good_string[index + 1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe6yWxMpcpnZ"
      },
      "source": [
        "Let's look at a few corrupted strings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iTTFSZdcpnZ",
        "outputId": "58f6c701-b5e9-426e-8614-6830f90874c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BTBPTTTPPXTVPXTTVPSETE BPBTXEEPE BPBPTVVVEPE BPBTSSSSXSETE BPTTXSEPE BTBPVPXTTTTTTEVETE BPBTXXSVEPE BSBPTTVPSETE BPBXVVEPE BEBTXSETE BPBPVPSXPE BTBPVVVETE BPBTSXSETE BPBPTTTPTTTTTVPSEPE BTBTXXTTSTVPSETE BBBTXSETE BPBTPXSEPE BPBPVPXTTTTVPXTVPXVPXTTTVVEVE BTBXXXTVPSETE BEBTSSSSSXXVPXTVVETE BTBXTTVVETE BPBTXSTPE BTBTXXTTTVPSBTE BTBTXSETX BTBTSXSSTE "
          ]
        }
      ],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "for _ in range(25):\n",
        "    print(generate_corrupted_string(embedded_reber_grammar), end=\" \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9frkK5s_cpnZ"
      },
      "source": [
        "We cannot feed strings directly to an RNN, so we need to encode them somehow. One option would be to one-hot encode each character. Another option is to use embeddings. Let's go for the second option (but since there are just a handful of characters, one-hot encoding would probably be a good option as well). For embeddings to work, we need to convert each string into a sequence of character IDs. Let's write a function for that, using each character's index in the string of possible characters \"BEPSTVX\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PscDNRS8cpnZ"
      },
      "outputs": [],
      "source": [
        "def string_to_ids(s, chars=POSSIBLE_CHARS):\n",
        "    return [chars.index(c) for c in s]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMTYOvbjcpnZ",
        "outputId": "1e638a4f-9da6-49d9-a162-96c7f376adc2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 4, 4, 4, 6, 6, 5, 5, 1, 4, 1]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "string_to_ids(\"BTTTXXVVETE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zthdZGakcpnZ"
      },
      "source": [
        "We can now generate the dataset, with 50% good strings, and 50% bad strings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsvxoRHocpna"
      },
      "outputs": [],
      "source": [
        "def generate_dataset(size):\n",
        "    good_strings = [\n",
        "        string_to_ids(generate_string(embedded_reber_grammar))\n",
        "        for _ in range(size // 2)\n",
        "    ]\n",
        "    bad_strings = [\n",
        "        string_to_ids(generate_corrupted_string(embedded_reber_grammar))\n",
        "        for _ in range(size - size // 2)\n",
        "    ]\n",
        "    all_strings = good_strings + bad_strings\n",
        "    X = tf.ragged.constant(all_strings, ragged_rank=1)\n",
        "    y = np.array([[1.] for _ in range(len(good_strings))] +\n",
        "                 [[0.] for _ in range(len(bad_strings))])\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvyNx9fOcpna"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "X_train, y_train = generate_dataset(10000)\n",
        "X_valid, y_valid = generate_dataset(2000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nDzi4Lucpna"
      },
      "source": [
        "Let's take a look at the first training sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFexOWn2cpna",
        "outputId": "9411d581-7e9d-4937-c448-a2b8f2a3bf88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(22,), dtype=int32, numpy=\n",
              "array([0, 4, 0, 2, 4, 4, 4, 5, 2, 6, 4, 5, 2, 6, 4, 4, 5, 2, 3, 1, 4, 1],\n",
              "      dtype=int32)>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TF_gQSJrcpna"
      },
      "source": [
        "What class does it belong to?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xQVKa0Tcpna",
        "outputId": "e7788c70-7229-4ce2-c710-9c42d1685843"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1.])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1cvlazKcpnb"
      },
      "source": [
        "Perfect! We are ready to create the RNN to identify good strings. We build a simple sequence binary classifier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9R0SK278cpnb",
        "outputId": "20722a40-821b-4565-c832-b251d336fb75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "313/313 [==============================] - 6s 8ms/step - loss: 0.6891 - accuracy: 0.5374 - val_loss: 0.6777 - val_accuracy: 0.4795\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.6624 - accuracy: 0.5695 - val_loss: 0.6582 - val_accuracy: 0.5285\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.6458 - accuracy: 0.5934 - val_loss: 0.6458 - val_accuracy: 0.5470\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.6266 - accuracy: 0.6093 - val_loss: 0.6264 - val_accuracy: 0.6375\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.5774 - accuracy: 0.6628 - val_loss: 0.5550 - val_accuracy: 0.7000\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.5082 - accuracy: 0.7414 - val_loss: 0.4907 - val_accuracy: 0.7485\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.4136 - accuracy: 0.8127 - val_loss: 0.3221 - val_accuracy: 0.8705\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2747 - accuracy: 0.8982 - val_loss: 0.1999 - val_accuracy: 0.9335\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.2106 - accuracy: 0.9291 - val_loss: 0.1412 - val_accuracy: 0.9555\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1232 - accuracy: 0.9647 - val_loss: 0.2249 - val_accuracy: 0.8965\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1534 - accuracy: 0.9543 - val_loss: 0.0785 - val_accuracy: 0.9805\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1790 - accuracy: 0.9422 - val_loss: 0.1286 - val_accuracy: 0.9695\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1308 - accuracy: 0.9636 - val_loss: 0.0989 - val_accuracy: 0.9740\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0845 - accuracy: 0.9810 - val_loss: 0.0742 - val_accuracy: 0.9825\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0744 - accuracy: 0.9838 - val_loss: 0.0712 - val_accuracy: 0.9850\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0731 - accuracy: 0.9839 - val_loss: 0.0757 - val_accuracy: 0.9850\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0725 - accuracy: 0.9839 - val_loss: 0.0685 - val_accuracy: 0.9850\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0732 - accuracy: 0.9839 - val_loss: 0.0679 - val_accuracy: 0.9850\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0730 - accuracy: 0.9839 - val_loss: 0.0700 - val_accuracy: 0.9850\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0733 - accuracy: 0.9839 - val_loss: 0.0682 - val_accuracy: 0.9850\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "embedding_size = 5\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=[None], dtype=tf.int32, ragged=True),\n",
        "    tf.keras.layers.Embedding(input_dim=len(POSSIBLE_CHARS),\n",
        "                              output_dim=embedding_size),\n",
        "    tf.keras.layers.GRU(30),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.02, momentum = 0.95,\n",
        "                                    nesterov=True)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train, epochs=20,\n",
        "                    validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FP00Z2-hAp1"
      },
      "source": [
        "Now let's test our RNN on two tricky strings: the first one is bad while the second one is good. They only differ by the second to last character. If the RNN gets this right, it shows that it managed to notice the pattern that the second letter should always be equal to the second to last letter. That requires a fairly long short-term memory (which is the reason why we used a GRU cell)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMyjHGi3hBB5",
        "outputId": "7e8b3e10-fac0-40c5-e194-06eea11e2107"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 311ms/step\n",
            "\n",
            "Estimated probability that these are Reber strings:\n",
            "BPBTSSSSSSSXXTTVPXVPXTTTTTVVETE: 98.52%\n",
            "BPBTSSSSSSSXXTTVPXVPXTTTTTVVEPE: 97.78%\n"
          ]
        }
      ],
      "source": [
        "test_strings = [\"BPBTSSSSSSSXXTTVPXVPXTTTTTVVETE\",\n",
        "                \"BPBTSSSSSSSXXTTVPXVPXTTTTTVVEPE\"]\n",
        "X_test = tf.ragged.constant([string_to_ids(s) for s in test_strings], ragged_rank=1)\n",
        "\n",
        "y_proba = model.predict(X_test)\n",
        "print()\n",
        "print(\"Estimated probability that these are Reber strings:\")\n",
        "for index, string in enumerate(test_strings):\n",
        "    print(\"{}: {:.2f}%\".format(string, 100 * y_proba[index][0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkzu0i9rhfet"
      },
      "source": [
        "Ta-da! It worked fine. The RNN found the correct answers with very high confidence. :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H36fg2jEhrAY"
      },
      "source": [
        "## 9.\n",
        "_Exercise: Train an Encoder–Decoder model that can convert a date string from one format to another (e.g., from \"April 22, 2019\" to \"2019-04-22\")._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBoQTshihtCX"
      },
      "source": [
        "Let's start by creating the dataset. We will use random days between 1000-01-01 and 9999-12-31:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMq55MbDhryP"
      },
      "outputs": [],
      "source": [
        "from datetime import date\n",
        "\n",
        "# cannot use strftime()'s %B format since it depends on the locale\n",
        "MONTHS = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\n",
        "          \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
        "\n",
        "def random_dates(n_dates):\n",
        "    min_date = date(1000, 1, 1).toordinal()\n",
        "    max_date = date(9999, 12, 31).toordinal()\n",
        "\n",
        "    ordinals = np.random.randint(max_date - min_date, size=n_dates) + min_date\n",
        "    dates = [date.fromordinal(ordinal) for ordinal in ordinals]\n",
        "\n",
        "    x = [MONTHS[dt.month - 1] + \" \" + dt.strftime(\"%d, %Y\") for dt in dates]\n",
        "    y = [dt.isoformat() for dt in dates]\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y45CaihOjpv_"
      },
      "source": [
        "Here are a few random dates, displayed in both the input format and the target format:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCQ0xhIcjjhH",
        "outputId": "cb80287a-0b18-4482-f7ef-da4b2fa1a6bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input                    Target                   \n",
            "--------------------------------------------------\n",
            "September 20, 7075       7075-09-20               \n",
            "May 15, 8579             8579-05-15               \n",
            "January 11, 7103         7103-01-11               \n"
          ]
        }
      ],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "n_dates = 3\n",
        "x_example, y_example = random_dates(n_dates)\n",
        "print(\"{:25s}{:25s}\".format(\"Input\", \"Target\"))\n",
        "print(\"-\" * 50)\n",
        "for idx in range(n_dates):\n",
        "    print(\"{:25s}{:25s}\".format(x_example[idx], y_example[idx]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxAjslYokXkg"
      },
      "source": [
        "Let's get the list of all possible characters in the inputs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xMSPm_MUkRSW",
        "outputId": "c270e875-b77f-4e1c-8033-4dfe95464ee3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' ,0123456789ADFJMNOSabceghilmnoprstuvy'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "INPUT_CHARS = \"\".join(sorted(set(\"\".join(MONTHS) + \"0123456789, \")))\n",
        "INPUT_CHARS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1c1FUBHkvFe"
      },
      "source": [
        "And here's the list of possible characters in the outputs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "duv3fAC0kphS",
        "outputId": "58b416ea-4745-4cc7-bce1-f7c93fd6c5af"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0123456789-'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "OUTPUT_CHARS = \"0123456789-\"\n",
        "OUTPUT_CHARS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-MBd1tsuwdI"
      },
      "source": [
        "Let's write a function to convert a string to a list of character IDs, as we did in the previous exercise:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yuj1-5Xkx9N"
      },
      "outputs": [],
      "source": [
        "def date_str_to_ids(date_str, chars=INPUT_CHARS):\n",
        "    return [chars.index(c) for c in date_str]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZ1nXKnKvTsa",
        "outputId": "2995d2fb-fed5-4194-efff-7ade3e299f91"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[19, 23, 31, 34, 23, 28, 21, 23, 32, 0, 4, 2, 1, 0, 9, 2, 9, 7]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "date_str_to_ids(x_example[0], INPUT_CHARS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiB-leBuvY_R",
        "outputId": "bc8173c2-39a2-49d9-f942-91a8216defda"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[7, 0, 7, 5, 10, 0, 9, 10, 2, 0]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "date_str_to_ids(y_example[0], OUTPUT_CHARS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUMsmyOhvj6W"
      },
      "outputs": [],
      "source": [
        "def prepare_date_strs(date_strs, chars=INPUT_CHARS):\n",
        "  X_ids = [date_str_to_ids(dt, chars) for dt in date_strs]\n",
        "  X = tf.ragged.constant(X_ids, ragged_rank=1)\n",
        "  return (X + 1).to_tensor()\n",
        "\n",
        "def create_dataset(n_dates):\n",
        "    x, y = random_dates(n_dates)\n",
        "    return prepare_date_strs(x, INPUT_CHARS), prepare_date_strs(y, OUTPUT_CHARS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoiQn81rw0hZ"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "X_train, Y_train = create_dataset(10000)\n",
        "X_valid, Y_valid = create_dataset(2000)\n",
        "X_test, Y_test = create_dataset(2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibK8IxsAxGlz",
        "outputId": "971c5d4f-1c30-427f-fce8-c595eccf9029"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 8,  1,  8,  6, 11,  1, 10, 11,  3,  1], dtype=int32)>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVHErqv_zUXb"
      },
      "source": [
        "### First version: a very basic seq2seq model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z680TgzBzSH8"
      },
      "source": [
        "Let's first try the simplest possible model: we feed in the input sequence, which first goes through the encoder (an embedding layer followed by a single LSTM layer), which outputs a vector, then it goes through a decoder (a single LSTM layer, followed by a dense output layer), which outputs a sequence of vectors, each representing the estimated probabilities for all possible output character.\n",
        "\n",
        "Since the decoder expects a sequence as input, we repeat the vector (which is output by the encoder) as many times as the longest possible output sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7D6g-4tjxQVR",
        "outputId": "cb0fbc83-ae08-4d7f-a98d-c78443515bb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "313/313 [==============================] - 10s 16ms/step - loss: 1.7048 - accuracy: 0.3915 - val_loss: 1.2457 - val_accuracy: 0.5583\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.3315 - accuracy: 0.5369 - val_loss: 1.0232 - val_accuracy: 0.6331\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.8343 - accuracy: 0.6955 - val_loss: 0.6990 - val_accuracy: 0.7416\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.8971 - accuracy: 0.6822 - val_loss: 0.6502 - val_accuracy: 0.7517\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.5285 - accuracy: 0.7961 - val_loss: 0.4344 - val_accuracy: 0.8288\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.3537 - accuracy: 0.8637 - val_loss: 0.2933 - val_accuracy: 0.8923\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2390 - accuracy: 0.9215 - val_loss: 0.1742 - val_accuracy: 0.9495\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1265 - accuracy: 0.9680 - val_loss: 0.1001 - val_accuracy: 0.9765\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.0709 - accuracy: 0.9861 - val_loss: 0.0585 - val_accuracy: 0.9880\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0393 - accuracy: 0.9951 - val_loss: 0.0344 - val_accuracy: 0.9952\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1211 - accuracy: 0.9735 - val_loss: 0.0309 - val_accuracy: 0.9962\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0201 - accuracy: 0.9986 - val_loss: 0.0179 - val_accuracy: 0.9981\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0125 - accuracy: 0.9994 - val_loss: 0.0126 - val_accuracy: 0.9987\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0086 - accuracy: 0.9998 - val_loss: 0.0091 - val_accuracy: 0.9994\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.0061 - accuracy: 0.9999 - val_loss: 0.0068 - val_accuracy: 0.9998\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 0.9999\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "embedding_size = 32\n",
        "max_output_length = Y_train.shape[1]\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "encoder = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=len(INPUT_CHARS) + 1,\n",
        "                           output_dim=embedding_size,\n",
        "                           input_shape=[None]),\n",
        "    tf.keras.layers.LSTM(128)\n",
        "])\n",
        "\n",
        "decoder = tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(128, return_sequences=True),\n",
        "    tf.keras.layers.Dense(len(OUTPUT_CHARS) + 1, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.RepeatVector(max_output_length),\n",
        "    decoder\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Nadam()\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, Y_train, epochs=20,\n",
        "                    validation_data=(X_valid, Y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_7rqTTk1XMb"
      },
      "source": [
        "Looks great, we reach 100% validation accuracy! Let's use the model to make some predictions. We will need to be able to convert a sequence of character IDs to a readable string:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBqqtu7p0lLc"
      },
      "outputs": [],
      "source": [
        "def ids_to_date_str(ids, chars=OUTPUT_CHARS):\n",
        "    return [\"\".join([(\"?\" + chars)[index] for index in sequence])\n",
        "            for sequence in ids]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miJXI5s43IeL"
      },
      "source": [
        "Now we can use the model to convert some dates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N26rhCcH3Kl6"
      },
      "outputs": [],
      "source": [
        "X_new = prepare_date_strs([\"september 17, 2009\", \"July 14, 1789\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdHdSvR63Yv4",
        "outputId": "e6633b28-c816-4222-818d-f4a7ea0ecc7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 643ms/step\n",
            "2009-12-17\n",
            "1789-07-14\n"
          ]
        }
      ],
      "source": [
        "ids = model.predict(X_new).argmax(axis=-1)\n",
        "for date_str in ids_to_date_str(ids):\n",
        "    print(date_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_gIG-oh3ojK"
      },
      "source": [
        "Perfect! :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3dDdbcf3p5y"
      },
      "source": [
        "However, since the model was only trained on input strings of length 18 (which is the length of the longest date), it does not perform well if we try to use it to make predictions on shorter sequences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkRBGOG53gUx"
      },
      "outputs": [],
      "source": [
        "X_new = prepare_date_strs([\"May 02, 2020\", \"July 14, 1789\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfCegbK431Hd",
        "outputId": "6eec43e1-3a3c-45cd-b269-f0b096866eb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 660ms/step\n",
            "2020-01-02\n",
            "1789-09-14\n"
          ]
        }
      ],
      "source": [
        "ids = model.predict(X_new).argmax(axis=-1)\n",
        "for date_str in ids_to_date_str(ids):\n",
        "    print(date_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kQk_0MW4CCy"
      },
      "source": [
        "Oops! We need to ensure that we always pass sequences of the same length as during training, using padding if necessary. Let's write a little helper function for that:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IEauOMv4Cxc"
      },
      "outputs": [],
      "source": [
        "max_input_length = X_train.shape[1]\n",
        "\n",
        "def prepare_date_strs_padded(date_strs):\n",
        "  X = prepare_date_strs(date_strs)\n",
        "  if X.shape[1] < max_input_length:\n",
        "    X = tf.pad(X, [[0, 0], [0, max_input_length - X.shape[1]]])\n",
        "  return X\n",
        "\n",
        "def convert_date_strs(date_strs):\n",
        "  X = prepare_date_strs_padded(date_strs)\n",
        "  ids = model.predict(X).argmax(axis=-1)\n",
        "  return ids_to_date_str(ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qE9tOpXK4lwo",
        "outputId": "aa0c6530-6693-42f7-aba9-6850894d384c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['2020-05-02', '1789-07-14']"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "convert_date_strs([\"May 02, 2020\", \"July 14, 1789\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB5SdB4i401p"
      },
      "source": [
        "Cool! Granted, there are certainly much easier ways to write a date conversion tool (e.g., using regular expressions or even basic string manipulation), but you have to admit that using neural networks is way cooler. ;-)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yb4jIG1741oB"
      },
      "source": [
        "However, real-life sequence-to-sequence problems will usually be harder, so for the sake of completeness, let's build a more powerful model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_KFuk9n43R5"
      },
      "source": [
        "### Second version: feeding the shifted targets to the decoder (teacher forcing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_9ONS3v5CCy"
      },
      "source": [
        "Instead of feeding the decoder a simple repetition of the encoder's output vector, we can feed it the target sequence, shifted by one time step to the right. This way, at each time step the decoder will know what the previous target character was. This should help is tackle more complex sequence-to-sequence problems.\n",
        "\n",
        "Since the first output character of each target sequence has no previous character, we will need a new token to represent the start-of-sequence (sos).\n",
        "\n",
        "During inference, we won't know the target, so what will we feed the decoder? We can just predict one character at a time, starting with an sos token, then feeding the decoder all the characters that were predicted so far (we will look at this in more details later in this notebook).\n",
        "\n",
        "But if the decoder's LSTM expects to get the previous target as input at each step, how shall we pass it it the vector output by the encoder? Well, one option is to ignore the output vector, and instead use the encoder's LSTM state as the initial state of the decoder's LSTM (which requires that encoder's LSTM must have the same number of units as the decoder's LSTM).\n",
        "\n",
        "Now let's create the decoder's inputs (for training, validation and testing). The sos token will be represented using the last possible output character's ID + 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxaxkFzH4uG5"
      },
      "outputs": [],
      "source": [
        "sos_id = len(OUTPUT_CHARS) + 1\n",
        "\n",
        "def shifted_output_sequences(Y):\n",
        "  sos_tokens = tf.fill(dims=(len(Y), 1), value=sos_id)\n",
        "  return tf.concat([sos_tokens, Y[:, :-1]], axis=1)\n",
        "\n",
        "X_train_decoder = shifted_output_sequences(Y_train)\n",
        "X_valid_decoder = shifted_output_sequences(Y_valid)\n",
        "X_test_decoder = shifted_output_sequences(Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RM8gpo558hEh"
      },
      "source": [
        "Let's take a look at the decoder's training inputs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsiBd4-x8crH",
        "outputId": "c445c0db-5ab3-4a4a-86bd-d130d4257b56"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10000, 10), dtype=int32, numpy=\n",
              "array([[12,  8,  1, ..., 10, 11,  3],\n",
              "       [12,  9,  6, ...,  6, 11,  2],\n",
              "       [12,  8,  2, ...,  2, 11,  2],\n",
              "       ...,\n",
              "       [12, 10,  8, ...,  2, 11,  4],\n",
              "       [12,  2,  2, ...,  3, 11,  3],\n",
              "       [12,  8,  9, ...,  8, 11,  3]], dtype=int32)>"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmCPISBF8sMi"
      },
      "source": [
        "Now let's build the model. It's not a simple sequential model anymore, so let's use the functional API:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9Qkg7xp8krT",
        "outputId": "2cd19792-507a-4f3f-c4a5-fcc82f683de0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "313/313 [==============================] - 10s 15ms/step - loss: 1.6362 - accuracy: 0.3843 - val_loss: 1.3766 - val_accuracy: 0.4784\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.1477 - accuracy: 0.5749 - val_loss: 0.8825 - val_accuracy: 0.6990\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.6334 - accuracy: 0.7827 - val_loss: 0.4485 - val_accuracy: 0.8443\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.2900 - accuracy: 0.9143 - val_loss: 0.1599 - val_accuracy: 0.9703\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1078 - accuracy: 0.9845 - val_loss: 0.0696 - val_accuracy: 0.9940\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0494 - accuracy: 0.9969 - val_loss: 0.0351 - val_accuracy: 0.9985\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0979 - accuracy: 0.9838 - val_loss: 0.0271 - val_accuracy: 0.9995\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0199 - accuracy: 0.9997 - val_loss: 0.0165 - val_accuracy: 0.9998\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0133 - accuracy: 0.9999 - val_loss: 0.0115 - val_accuracy: 0.9999\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0093 - accuracy: 0.9999 - val_loss: 0.0098 - val_accuracy: 0.9998\n"
          ]
        }
      ],
      "source": [
        "encoder_embedding_size = 32\n",
        "decoder_embedding_size = 32\n",
        "lstm_units = 128\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "encoder_input = tf.keras.layers.Input(shape=[None], dtype=tf.int32)\n",
        "encoder_embedding = tf.keras.layers.Embedding(\n",
        "    input_dim=len(INPUT_CHARS) + 1,\n",
        "    output_dim=encoder_embedding_size)(encoder_input)\n",
        "_, encoder_state_h, encoder_state_c = tf.keras.layers.LSTM(\n",
        "    lstm_units, return_state=True)(encoder_embedding)\n",
        "encoder_state = [encoder_state_h, encoder_state_c]\n",
        "\n",
        "decoder_input = tf.keras.layers.Input(shape=[None], dtype=tf.int32)\n",
        "decoder_embedding = tf.keras.layers.Embedding(\n",
        "    input_dim=len(OUTPUT_CHARS) + 2,\n",
        "    output_dim=decoder_embedding_size)(decoder_input)\n",
        "decoder_lstm_output = tf.keras.layers.LSTM(lstm_units, return_sequences=True)(\n",
        "    decoder_embedding, initial_state=encoder_state)\n",
        "decoder_output = tf.keras.layers.Dense(len(OUTPUT_CHARS) + 1,\n",
        "                                    activation=\"softmax\")(decoder_lstm_output)\n",
        "\n",
        "model = tf.keras.Model(inputs=[encoder_input, decoder_input],\n",
        "                           outputs=[decoder_output])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Nadam()\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "history = model.fit([X_train, X_train_decoder], Y_train, epochs=10,\n",
        "                    validation_data=([X_valid, X_valid_decoder], Y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWNVcDlHFMDF"
      },
      "source": [
        "This model also reaches 100% validation accuracy, but it does so even faster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZARs4ocWFNnF"
      },
      "source": [
        "Let's once again use the model to make some predictions. This time we need to predict characters one by one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vs48Y37i_5Ca"
      },
      "outputs": [],
      "source": [
        "sos_id = len(OUTPUT_CHARS) + 1\n",
        "\n",
        "def predict_date_strs(date_strs):\n",
        "  X = prepare_date_strs_padded(date_strs)\n",
        "  Y_pred = tf.fill(dims=(len(X), 1), value=sos_id)\n",
        "  for index in range(max_output_length):\n",
        "    pad_size = max_output_length - Y_pred.shape[1]\n",
        "    X_decoder = tf.pad(Y_pred, [[0, 0], [0, pad_size]])\n",
        "    Y_probas_next = model.predict([X, X_decoder])[:, index:index+1]\n",
        "    Y_pred_next = tf.argmax(Y_probas_next, axis=-1, output_type=tf.int32)\n",
        "    Y_pred = tf.concat([Y_pred, Y_pred_next], axis=1)\n",
        "  return ids_to_date_str(Y_pred[:, 1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTjbLOt3GsgS",
        "outputId": "f48b9bd5-5e3b-460c-e437-e7caa4cb4871"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 671ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['1789-07-14', '2020-05-02']"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict_date_strs([\"July 14, 1789\", \"May 02, 2020\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHwoP6LjG5hC"
      },
      "source": [
        "Works fine! Next, feel free to write a Transformer version. :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUlqJ84tL1eI"
      },
      "source": [
        "## 10.\n",
        "\n",
        "Exercise: Go through Keras's tutorial for Natural language image search with a Dual Encoder. You will learn how to build a model capable of representing both images and text within the same embedding space. This makes it possible to search for images using a text prompt, like in the CLIP model by OpenAI.\n",
        "\n",
        "Just click the link and follow the instructions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drpmWkhyjo5u"
      },
      "source": [
        "###Introduction\n",
        "The example demonstrates how to build a dual encoder (also known as two-tower) neural network model to search for images using natural language. The model is inspired by the CLIP approach, introduced by Alec Radford et al. The idea is to train a vision encoder and a text encoder jointly to project the representation of images and their captions into the same embedding space, such that the caption embeddings are located near the embeddings of the images they describe.\n",
        "\n",
        "This example requires TensorFlow 2.4 or higher. In addition, TensorFlow Hub and TensorFlow Text are required for the BERT model, and TensorFlow Addons is required for the AdamW optimizer. These libraries can be installed using the following command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJbsP8_qjsPh",
        "outputId": "d8f942ca-7dac-4a19-b07c-30e9a673bb62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "pip install -q -U tensorflow-hub tensorflow-text tensorflow-addons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iIlwEnXMSRX"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "52ryqXgmG53Q",
        "outputId": "78b88822-ee2b-465b-b9c0-1530c70a3fe2"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'keras.src.engine'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-79cb9f682270>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_hub\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_text\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_addons/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Local project imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_addons/activations/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"Additional activation functions.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgelu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhardshrink\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhardshrink\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlisht\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlisht\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_addons/activations/gelu.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorLike\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/types.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# New versions of Keras require importing from `keras.src` when\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# importing internal symbols.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2.5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.src.engine'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import collections\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "import tensorflow_addons as tfa\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Suppressing tf.hub warnings\n",
        "tf.get_logger().setLevel(\"ERROR\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7cRhgBpjjJH"
      },
      "source": [
        "### Prepare the data\n",
        "We will use the MS-COCO dataset to train our dual encoder model. MS-COCO contains over 82,000 images, each of which has at least 5 different caption annotations. The dataset is usually used for image captioning tasks, but we can repurpose the image-caption pairs to train our dual encoder model for image search.\n",
        "\n",
        "Download and extract the data\n",
        "\n",
        "First, let's download the dataset, which consists of two compressed folders: one with images, and the other—with associated image captions. Note that the compressed images folder is 13GB in size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gHLkpCIMUpN"
      },
      "outputs": [],
      "source": [
        "root_dir = \"datasets\"\n",
        "annotations_dir = os.path.join(root_dir, \"annotations\")\n",
        "images_dir = os.path.join(root_dir, \"train2014\")\n",
        "tfrecords_dir = os.path.join(root_dir, \"tfrecords\")\n",
        "annotation_file = os.path.join(annotations_dir, \"captions_train2014.json\")\n",
        "\n",
        "# Download caption annotation files\n",
        "if not os.path.exists(annotations_dir):\n",
        "    annotation_zip = tf.keras.utils.get_file(\n",
        "        \"captions.zip\",\n",
        "        cache_dir=os.path.abspath(\".\"),\n",
        "        origin=\"http://images.cocodataset.org/annotations/annotations_trainval2014.zip\",\n",
        "        extract=True,\n",
        "    )\n",
        "    os.remove(annotation_zip)\n",
        "\n",
        "# Download image files\n",
        "if not os.path.exists(images_dir):\n",
        "    image_zip = tf.keras.utils.get_file(\n",
        "        \"train2014.zip\",\n",
        "        cache_dir=os.path.abspath(\".\"),\n",
        "        origin=\"http://images.cocodataset.org/zips/train2014.zip\",\n",
        "        extract=True,\n",
        "    )\n",
        "    os.remove(image_zip)\n",
        "\n",
        "print(\"Dataset is downloaded and extracted successfully.\")\n",
        "\n",
        "with open(annotation_file, \"r\") as f:\n",
        "    annotations = json.load(f)[\"annotations\"]\n",
        "\n",
        "image_path_to_caption = collections.defaultdict(list)\n",
        "for element in annotations:\n",
        "    caption = f\"{element['caption'].lower().rstrip('.')}\"\n",
        "    image_path = images_dir + \"/COCO_train2014_\" + \"%012d.jpg\" % (element[\"image_id\"])\n",
        "    image_path_to_caption[image_path].append(caption)\n",
        "\n",
        "image_paths = list(image_path_to_caption.keys())\n",
        "print(f\"Number of images: {len(image_paths)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEkv_z6SkHAv"
      },
      "source": [
        "###Process and save the data to TFRecord files\n",
        "You can change the sample_size parameter to control many image-caption pairs will be used for training the dual encoder model. In this example we set train_size to 30,000 images, which is about 35% of the dataset. We use 2 captions for each image, thus producing 60,000 image-caption pairs. The size of the training set affects the quality of the produced encoders, but more examples would lead to longer training time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qn_jCq5xkNOM"
      },
      "outputs": [],
      "source": [
        "train_size = 30000\n",
        "valid_size = 5000\n",
        "captions_per_image = 2\n",
        "images_per_file = 2000\n",
        "\n",
        "train_image_paths = image_paths[:train_size]\n",
        "num_train_files = int(np.ceil(train_size / images_per_file))\n",
        "train_files_prefix = os.path.join(tfrecords_dir, \"train\")\n",
        "\n",
        "valid_image_paths = image_paths[-valid_size:]\n",
        "num_valid_files = int(np.ceil(valid_size / images_per_file))\n",
        "valid_files_prefix = os.path.join(tfrecords_dir, \"valid\")\n",
        "\n",
        "tf.io.gfile.makedirs(tfrecords_dir)\n",
        "\n",
        "\n",
        "def bytes_feature(value):\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "\n",
        "def create_example(image_path, caption):\n",
        "    feature = {\n",
        "        \"caption\": bytes_feature(caption.encode()),\n",
        "        \"raw_image\": bytes_feature(tf.io.read_file(image_path).numpy()),\n",
        "    }\n",
        "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "\n",
        "def write_tfrecords(file_name, image_paths):\n",
        "    caption_list = []\n",
        "    image_path_list = []\n",
        "    for image_path in image_paths:\n",
        "        captions = image_path_to_caption[image_path][:captions_per_image]\n",
        "        caption_list.extend(captions)\n",
        "        image_path_list.extend([image_path] * len(captions))\n",
        "\n",
        "    with tf.io.TFRecordWriter(file_name) as writer:\n",
        "        for example_idx in range(len(image_path_list)):\n",
        "            example = create_example(\n",
        "                image_path_list[example_idx], caption_list[example_idx]\n",
        "            )\n",
        "            writer.write(example.SerializeToString())\n",
        "    return example_idx + 1\n",
        "\n",
        "\n",
        "def write_data(image_paths, num_files, files_prefix):\n",
        "    example_counter = 0\n",
        "    for file_idx in tqdm(range(num_files)):\n",
        "        file_name = files_prefix + \"-%02d.tfrecord\" % (file_idx)\n",
        "        start_idx = images_per_file * file_idx\n",
        "        end_idx = start_idx + images_per_file\n",
        "        example_counter += write_tfrecords(file_name, image_paths[start_idx:end_idx])\n",
        "    return example_counter\n",
        "\n",
        "\n",
        "train_example_count = write_data(train_image_paths, num_train_files, train_files_prefix)\n",
        "print(f\"{train_example_count} training examples were written to tfrecord files.\")\n",
        "\n",
        "valid_example_count = write_data(valid_image_paths, num_valid_files, valid_files_prefix)\n",
        "print(f\"{valid_example_count} evaluation examples were written to tfrecord files.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvFjRMYxka6U"
      },
      "source": [
        "###Create tf.data.Dataset for training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I62cZhz-kcef"
      },
      "outputs": [],
      "source": [
        "feature_description = {\n",
        "    \"caption\": tf.io.FixedLenFeature([], tf.string),\n",
        "    \"raw_image\": tf.io.FixedLenFeature([], tf.string),\n",
        "}\n",
        "\n",
        "\n",
        "def read_example(example):\n",
        "    features = tf.io.parse_single_example(example, feature_description)\n",
        "    raw_image = features.pop(\"raw_image\")\n",
        "    features[\"image\"] = tf.image.resize(\n",
        "        tf.image.decode_jpeg(raw_image, channels=3), size=(299, 299)\n",
        "    )\n",
        "    return features\n",
        "\n",
        "\n",
        "def get_dataset(file_pattern, batch_size):\n",
        "\n",
        "    return (\n",
        "        tf.data.TFRecordDataset(tf.data.Dataset.list_files(file_pattern))\n",
        "        .map(\n",
        "            read_example,\n",
        "            num_parallel_calls=tf.data.AUTOTUNE,\n",
        "            deterministic=False,\n",
        "        )\n",
        "        .shuffle(batch_size * 10)\n",
        "        .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "        .batch(batch_size)\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdt5J0YEkgf8"
      },
      "source": [
        "###Implement the projection head\n",
        "The projection head is used to transform the image and the text embeddings to the same embedding space with the same dimensionality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ws2WK_TgkjVE"
      },
      "outputs": [],
      "source": [
        "def project_embeddings(\n",
        "    embeddings, num_projection_layers, projection_dims, dropout_rate\n",
        "):\n",
        "    projected_embeddings = layers.Dense(units=projection_dims)(embeddings)\n",
        "    for _ in range(num_projection_layers):\n",
        "        x = tf.nn.gelu(projected_embeddings)\n",
        "        x = layers.Dense(projection_dims)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "        x = layers.Add()([projected_embeddings, x])\n",
        "        projected_embeddings = layers.LayerNormalization()(x)\n",
        "    return projected_embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSAUN9kjknwE"
      },
      "source": [
        "###Implement the vision encoder\n",
        "In this example, we use Xception from Keras Applications as the base for the vision encoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baBok5y1kpXY"
      },
      "outputs": [],
      "source": [
        "def create_vision_encoder(\n",
        "    num_projection_layers, projection_dims, dropout_rate, trainable=False\n",
        "):\n",
        "    # Load the pre-trained Xception model to be used as the base encoder.\n",
        "    xception = keras.applications.Xception(\n",
        "        include_top=False, weights=\"imagenet\", pooling=\"avg\"\n",
        "    )\n",
        "    # Set the trainability of the base encoder.\n",
        "    for layer in xception.layers:\n",
        "        layer.trainable = trainable\n",
        "    # Receive the images as inputs.\n",
        "    inputs = layers.Input(shape=(299, 299, 3), name=\"image_input\")\n",
        "    # Preprocess the input image.\n",
        "    xception_input = tf.keras.applications.xception.preprocess_input(inputs)\n",
        "    # Generate the embeddings for the images using the xception model.\n",
        "    embeddings = xception(xception_input)\n",
        "    # Project the embeddings produced by the model.\n",
        "    outputs = project_embeddings(\n",
        "        embeddings, num_projection_layers, projection_dims, dropout_rate\n",
        "    )\n",
        "    # Create the vision encoder model.\n",
        "    return keras.Model(inputs, outputs, name=\"vision_encoder\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufbjHm-MktB2"
      },
      "source": [
        "###Implement the text encoder\n",
        "We use BERT from TensorFlow Hub as the text encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHUjaJj0kvPf"
      },
      "outputs": [],
      "source": [
        "def create_text_encoder(\n",
        "    num_projection_layers, projection_dims, dropout_rate, trainable=False\n",
        "):\n",
        "    # Load the BERT preprocessing module.\n",
        "    preprocess = hub.KerasLayer(\n",
        "        \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2\",\n",
        "        name=\"text_preprocessing\",\n",
        "    )\n",
        "    # Load the pre-trained BERT model to be used as the base encoder.\n",
        "    bert = hub.KerasLayer(\n",
        "        \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\",\n",
        "        \"bert\",\n",
        "    )\n",
        "    # Set the trainability of the base encoder.\n",
        "    bert.trainable = trainable\n",
        "    # Receive the text as inputs.\n",
        "    inputs = layers.Input(shape=(), dtype=tf.string, name=\"text_input\")\n",
        "    # Preprocess the text.\n",
        "    bert_inputs = preprocess(inputs)\n",
        "    # Generate embeddings for the preprocessed text using the BERT model.\n",
        "    embeddings = bert(bert_inputs)[\"pooled_output\"]\n",
        "    # Project the embeddings produced by the model.\n",
        "    outputs = project_embeddings(\n",
        "        embeddings, num_projection_layers, projection_dims, dropout_rate\n",
        "    )\n",
        "    # Create the text encoder model.\n",
        "    return keras.Model(inputs, outputs, name=\"text_encoder\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWxQ85zSkzms"
      },
      "source": [
        "###Implement the dual encoder\n",
        "To calculate the loss, we compute the pairwise dot-product similarity between each caption_i and images_j in the batch as the predictions. The target similarity between caption_i and image_j is computed as the average of the (dot-product similarity between caption_i and caption_j) and (the dot-product similarity between image_i and image_j). Then, we use crossentropy to compute the loss between the targets and the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tt1Jsczbk03d"
      },
      "outputs": [],
      "source": [
        "class DualEncoder(keras.Model):\n",
        "    def __init__(self, text_encoder, image_encoder, temperature=1.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.text_encoder = text_encoder\n",
        "        self.image_encoder = image_encoder\n",
        "        self.temperature = temperature\n",
        "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_tracker]\n",
        "\n",
        "    def call(self, features, training=False):\n",
        "        # Place each encoder on a separate GPU (if available).\n",
        "        # TF will fallback on available devices if there are fewer than 2 GPUs.\n",
        "        with tf.device(\"/gpu:0\"):\n",
        "            # Get the embeddings for the captions.\n",
        "            caption_embeddings = text_encoder(features[\"caption\"], training=training)\n",
        "        with tf.device(\"/gpu:1\"):\n",
        "            # Get the embeddings for the images.\n",
        "            image_embeddings = vision_encoder(features[\"image\"], training=training)\n",
        "        return caption_embeddings, image_embeddings\n",
        "\n",
        "    def compute_loss(self, caption_embeddings, image_embeddings):\n",
        "        # logits[i][j] is the dot_similarity(caption_i, image_j).\n",
        "        logits = (\n",
        "            tf.matmul(caption_embeddings, image_embeddings, transpose_b=True)\n",
        "            / self.temperature\n",
        "        )\n",
        "        # images_similarity[i][j] is the dot_similarity(image_i, image_j).\n",
        "        images_similarity = tf.matmul(\n",
        "            image_embeddings, image_embeddings, transpose_b=True\n",
        "        )\n",
        "        # captions_similarity[i][j] is the dot_similarity(caption_i, caption_j).\n",
        "        captions_similarity = tf.matmul(\n",
        "            caption_embeddings, caption_embeddings, transpose_b=True\n",
        "        )\n",
        "        # targets[i][j] = avarage dot_similarity(caption_i, caption_j) and dot_similarity(image_i, image_j).\n",
        "        targets = keras.activations.softmax(\n",
        "            (captions_similarity + images_similarity) / (2 * self.temperature)\n",
        "        )\n",
        "        # Compute the loss for the captions using crossentropy\n",
        "        captions_loss = keras.losses.categorical_crossentropy(\n",
        "            y_true=targets, y_pred=logits, from_logits=True\n",
        "        )\n",
        "        # Compute the loss for the images using crossentropy\n",
        "        images_loss = keras.losses.categorical_crossentropy(\n",
        "            y_true=tf.transpose(targets), y_pred=tf.transpose(logits), from_logits=True\n",
        "        )\n",
        "        # Return the mean of the loss over the batch.\n",
        "        return (captions_loss + images_loss) / 2\n",
        "\n",
        "    def train_step(self, features):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass\n",
        "            caption_embeddings, image_embeddings = self(features, training=True)\n",
        "            loss = self.compute_loss(caption_embeddings, image_embeddings)\n",
        "        # Backward pass\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        # Monitor loss\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        return {\"loss\": self.loss_tracker.result()}\n",
        "\n",
        "    def test_step(self, features):\n",
        "        caption_embeddings, image_embeddings = self(features, training=False)\n",
        "        loss = self.compute_loss(caption_embeddings, image_embeddings)\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        return {\"loss\": self.loss_tracker.result()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvBwrnipk4-t"
      },
      "source": [
        "###Train the dual encoder model\n",
        "In this experiment, we freeze the base encoders for text and images, and make only the projection head trainable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKJ0ws6fk7Qf"
      },
      "outputs": [],
      "source": [
        "num_epochs = 5  # In practice, train for at least 30 epochs\n",
        "batch_size = 256\n",
        "\n",
        "vision_encoder = create_vision_encoder(\n",
        "    num_projection_layers=1, projection_dims=256, dropout_rate=0.1\n",
        ")\n",
        "text_encoder = create_text_encoder(\n",
        "    num_projection_layers=1, projection_dims=256, dropout_rate=0.1\n",
        ")\n",
        "dual_encoder = DualEncoder(text_encoder, vision_encoder, temperature=0.05)\n",
        "dual_encoder.compile(\n",
        "    optimizer=tfa.optimizers.AdamW(learning_rate=0.001, weight_decay=0.001)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oI5yUhJmk9dU"
      },
      "source": [
        "Note that training the model with 60,000 image-caption pairs, with a batch size of 256, takes around 12 minutes per epoch using a V100 GPU accelerator. If 2 GPUs are available, the epoch takes around 8 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghbik14gk-og"
      },
      "outputs": [],
      "source": [
        "print(f\"Number of GPUs: {len(tf.config.list_physical_devices('GPU'))}\")\n",
        "print(f\"Number of examples (caption-image pairs): {train_example_count}\")\n",
        "print(f\"Batch size: {batch_size}\")\n",
        "print(f\"Steps per epoch: {int(np.ceil(train_example_count / batch_size))}\")\n",
        "train_dataset = get_dataset(os.path.join(tfrecords_dir, \"train-*.tfrecord\"), batch_size)\n",
        "valid_dataset = get_dataset(os.path.join(tfrecords_dir, \"valid-*.tfrecord\"), batch_size)\n",
        "# Create a learning rate scheduler callback.\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\", factor=0.2, patience=3\n",
        ")\n",
        "# Create an early stopping callback.\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\", patience=5, restore_best_weights=True\n",
        ")\n",
        "history = dual_encoder.fit(\n",
        "    train_dataset,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=valid_dataset,\n",
        "    callbacks=[reduce_lr, early_stopping],\n",
        ")\n",
        "print(\"Training completed. Saving vision and text encoders...\")\n",
        "vision_encoder.save(\"vision_encoder\")\n",
        "text_encoder.save(\"text_encoder\")\n",
        "print(\"Models are saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1NZI4mOlCcc"
      },
      "source": [
        "Plotting the training loss:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciZZNrsXlC1v"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"train\", \"valid\"], loc=\"upper right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXcIJEl3lGUE"
      },
      "source": [
        "###Search for images using natural language queries\n",
        "We can then retrieve images corresponding to natural language queries via the following steps:\n",
        "\n",
        "Generate embeddings for the images by feeding them into the vision_encoder.\n",
        "Feed the natural language query to the text_encoder to generate a query embedding.\n",
        "Compute the similarity between the query embedding and the image embeddings in the index to retrieve the indices of the top matches.\n",
        "Look up the paths of the top matching images to display them.\n",
        "Note that, after training the dual encoder, only the fine-tuned vision_encoder and text_encoder models will be used, while the dual_encoder model will be discarded.\n",
        "\n",
        "####Generate embeddings for the images\n",
        "We load the images and feed them into the vision_encoder to generate their embeddings. In large scale systems, this step is performed using a parallel data processing framework, such as Apache Spark or Apache Beam. Generating the image embeddings may take several minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3T3Buo5lJd5"
      },
      "outputs": [],
      "source": [
        "print(\"Loading vision and text encoders...\")\n",
        "vision_encoder = keras.models.load_model(\"vision_encoder\")\n",
        "text_encoder = keras.models.load_model(\"text_encoder\")\n",
        "print(\"Models are loaded.\")\n",
        "\n",
        "\n",
        "def read_image(image_path):\n",
        "    image_array = tf.image.decode_jpeg(tf.io.read_file(image_path), channels=3)\n",
        "    return tf.image.resize(image_array, (299, 299))\n",
        "\n",
        "\n",
        "print(f\"Generating embeddings for {len(image_paths)} images...\")\n",
        "image_embeddings = vision_encoder.predict(\n",
        "    tf.data.Dataset.from_tensor_slices(image_paths).map(read_image).batch(batch_size),\n",
        "    verbose=1,\n",
        ")\n",
        "print(f\"Image embeddings shape: {image_embeddings.shape}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owdT5BwTlMm8"
      },
      "source": [
        "###Retrieve relevant images\n",
        "In this example, we use exact matching by computing the dot product similarity between the input query embedding and the image embeddings, and retrieve the top k matches. However, approximate similarity matching, using frameworks like ScaNN, Annoy, or Faiss is preferred in real-time use cases to scale with a large number of images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-b7YASeflP_L"
      },
      "outputs": [],
      "source": [
        "def find_matches(image_embeddings, queries, k=9, normalize=True):\n",
        "    # Get the embedding for the query.\n",
        "    query_embedding = text_encoder(tf.convert_to_tensor(queries))\n",
        "    # Normalize the query and the image embeddings.\n",
        "    if normalize:\n",
        "        image_embeddings = tf.math.l2_normalize(image_embeddings, axis=1)\n",
        "        query_embedding = tf.math.l2_normalize(query_embedding, axis=1)\n",
        "    # Compute the dot product between the query and the image embeddings.\n",
        "    dot_similarity = tf.matmul(query_embedding, image_embeddings, transpose_b=True)\n",
        "    # Retrieve top k indices.\n",
        "    results = tf.math.top_k(dot_similarity, k).indices.numpy()\n",
        "    # Return matching image paths.\n",
        "    return [[image_paths[idx] for idx in indices] for indices in results]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlwHxcxJlTRT"
      },
      "source": [
        "Set the query variable to the type of images you want to search for. Try things like: 'a plate of healthy food', 'a woman wearing a hat is walking down a sidewalk', 'a bird sits near to the water', or 'wild animals are standing in a field'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IObv3WmWlTs-"
      },
      "outputs": [],
      "source": [
        "query = \"a family standing next to the ocean on a sandy beach with a surf board\"\n",
        "matches = find_matches(image_embeddings, [query], normalize=True)[0]\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(mpimg.imread(matches[i]))\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erboAMnSlXQt"
      },
      "source": [
        "###Evaluate the retrieval quality\n",
        "To evaluate the dual encoder model, we use the captions as queries. We use the out-of-training-sample images and captions to evaluate the retrieval quality, using top k accuracy. A true prediction is counted if, for a given caption, its associated image is retrieved within the top k matches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRYBCQlslZBv"
      },
      "outputs": [],
      "source": [
        "def compute_top_k_accuracy(image_paths, k=100):\n",
        "    hits = 0\n",
        "    num_batches = int(np.ceil(len(image_paths) / batch_size))\n",
        "    for idx in tqdm(range(num_batches)):\n",
        "        start_idx = idx * batch_size\n",
        "        end_idx = start_idx + batch_size\n",
        "        current_image_paths = image_paths[start_idx:end_idx]\n",
        "        queries = [\n",
        "            image_path_to_caption[image_path][0] for image_path in current_image_paths\n",
        "        ]\n",
        "        result = find_matches(image_embeddings, queries, k)\n",
        "        hits += sum(\n",
        "            [\n",
        "                image_path in matches\n",
        "                for (image_path, matches) in list(zip(current_image_paths, result))\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    return hits / len(image_paths)\n",
        "\n",
        "\n",
        "print(\"Scoring training data...\")\n",
        "train_accuracy = compute_top_k_accuracy(train_image_paths)\n",
        "print(f\"Train accuracy: {round(train_accuracy * 100, 3)}%\")\n",
        "\n",
        "print(\"Scoring evaluation data...\")\n",
        "eval_accuracy = compute_top_k_accuracy(image_paths[train_size:])\n",
        "print(f\"Eval accuracy: {round(eval_accuracy * 100, 3)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPgZJXkKldFV"
      },
      "source": [
        "Final remarks\n",
        "You can obtain better results by increasing the size of the training sample, train for more epochs, explore other base encoders for images and text, set the base encoders to be trainable, and tune the hyperparameters, especially the temperature for the softmax in the loss computation.\n",
        "\n",
        "Example available on HuggingFace\n",
        "\n",
        "\n",
        "Trained Model\n",
        "\n",
        "https://huggingface.co/keras-io/dual-encoder-image-search\n",
        "\n",
        "\n",
        "Demo\n",
        "\n",
        "https://huggingface.co/spaces/keras-io/dual-encoder-image-search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYGZ9MzeXO3d"
      },
      "source": [
        "## 11.\n",
        "Exercise: Use the Transformers library to download a pretrained language model capable of generating text (e.g., GPT), and try generating more convincing Shakespearean text. You will need to use the model's generate() method—see Hugging Face's documentation for more details.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwbchCH6XrU3"
      },
      "source": [
        "First, let's load a pretrained model. In this example, we will use OpenAI's GPT model, with an additional Language Model on top (just a linear layer with weights tied to the input embeddings). Let's import it and load the pretrained weights (this will download about 445MB of data to ~/.cache/torch/transformers):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "e6e36a23c0c64576ba789ece88971c39",
            "1dec3d2c90b6415b86dde608f1c64a0e",
            "1ac71c54dfb84c269b241c0be220f3c9",
            "bb34946d8176431b872876a898fa7f15",
            "063a0557e7ce431f8e94bd19289ccf75",
            "6e1ebe89c1de4ac98885c7da6bbf447e",
            "5cf768c45600400bb2986b88bb8d7a45",
            "2be12563a7ff49f1ae0b3254faf383b1",
            "04363da2c644495fa19ccdad1ecc648a",
            "70e70b06a2b64eed9db33e6522bfc892",
            "45c70ab7a251408083d3a357d2fb4cca",
            "82733b6c252a4f7682c06b92818c06f6",
            "60403cd0e9d24e29b652f035f7f411d1",
            "08e08406ec694e158255350e115660ea",
            "8f604590bca0467e95dedfabdddc9217",
            "577589a2c1344c009505cb1e6ed85192",
            "ac52321eda81487a82bcde0c698f2267",
            "96bc7f56a2a9430ba5250da09bb3ce4b",
            "b3df2339cdee4667b662f943f4009500",
            "46b37369cdf544a3bebbc2b3ecb7f4fd",
            "8c40845e997b4b4281279e3befdd796b",
            "95da085a0ce1488d8dbc86a982765001"
          ]
        },
        "id": "LfF0DfwCXR1X",
        "outputId": "6e9643d4-b98e-426c-8895-0f498cf397d1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6e36a23c0c64576ba789ece88971c39",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/656 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82733b6c252a4f7682c06b92818c06f6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/479M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFOpenAIGPTLMHeadModel: ['h.2.attn.bias', 'h.7.attn.bias', 'h.6.attn.bias', 'h.3.attn.bias', 'h.0.attn.bias', 'h.9.attn.bias', 'h.10.attn.bias', 'h.4.attn.bias', 'h.11.attn.bias', 'h.5.attn.bias', 'h.1.attn.bias', 'h.8.attn.bias']\n",
            "- This IS expected if you are initializing TFOpenAIGPTLMHeadModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFOpenAIGPTLMHeadModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFOpenAIGPTLMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFOpenAIGPTLMHeadModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFOpenAIGPTLMHeadModel\n",
        "\n",
        "model = TFOpenAIGPTLMHeadModel.from_pretrained(\"openai-gpt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8mckitqYngm"
      },
      "source": [
        "Next we will need a specialized tokenizer for this model. This one will try to use the [spaCy](https://spacy.io/) and [ftfy](https://pypi.org/project/ftfy/) libraries if they are installed, or else it will fall back to BERT's `BasicTokenizer` followed by Byte-Pair Encoding (which should be fine for most use cases)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162,
          "referenced_widgets": [
            "cf9b0f4ad2e64396974b254ae072c045",
            "ff6388e7208943ef814edae516394dcf",
            "1f78001e88274b6094a55ab5cbaf18bf",
            "23d931e144464016b113afdab954c762",
            "8344db2b95df40868d4ad5f93876a042",
            "f146dd3aff204c3d982471f83e596adb",
            "7c89ce4b91054c878bdae74e690c68f8",
            "08d13b02696944e4bd931448db6fe4a8",
            "84221077b1834020bac468b0319b48af",
            "15603e73f1394e658e93e7a9ba519aca",
            "b6371f1b7ca948eb9005c2217326069c",
            "399820251d71491dad82a6c327f2d235",
            "df6dcba2d75d4673be0f7fef28281ead",
            "63de6a75af7f4e92a1266f0ae9b60307",
            "67430626511144cc8842ee799fccb486",
            "725105d85216425f9396daaab21524d1",
            "bf2228f3cf4443469bee101f6637a27b",
            "06366a00c73f4907bcea01b6206d923a",
            "a2836f92050e477ba45c3a984879093e",
            "83666078d0d84aa4af8aabca17403722",
            "ccce58d4096742bb9375c30ecd18dce2",
            "6858d26e35564029a0d8e5d23c221ee3",
            "fa1ca802baa544208c121c7fd0b5e019",
            "c18f6ea268644b47a376f240c25bde7d",
            "f35a55a913a34f8283b0a13a614825f7",
            "7ffd99a522f146bfb7a59b5e20044bd1",
            "7b4a0f19b69d487e84201bdb873fd70f",
            "d9853dafcbca4d54854c683313bab9fb",
            "6856faa9e01f4f338e8337d8acf36af4",
            "e990c3368b0e4657b94e60649c13709b",
            "69e22e219d204c14aeb1819d5e685087",
            "775ba2861b3c438a81d9fc22e727f5ae",
            "967c6f8ee0984d7c9289f8e6af1a27b3",
            "897129bb300c419e8c896d528ff0f8cd",
            "05fc2b0a802e4e88946d3a7eb45d0607",
            "84919481c9214616b01b15ba955a72dd",
            "a2b15a0c56234745a39b4c0a1aa5e8b8",
            "b8133c451d1f4d319b4c4b79af16b000",
            "f2ca3c6f144d48e49fb6d225aeb1fa62",
            "113c339546c14dcaaaaa2ea2946f60e3",
            "3007749421004bcbb7cccac799acbb30",
            "96bf2cfc2ab74d30aeee7ccc739ab9c1",
            "243addd7aeef4d059943db1adb76094e",
            "945b5ce3f3b44cc0a06b61501cdc0616"
          ]
        },
        "id": "8IbHdDfdYC2g",
        "outputId": "13c00734-bff4-4f2b-bb0f-be4ef0b64c24"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf9b0f4ad2e64396974b254ae072c045",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "399820251d71491dad82a6c327f2d235",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/816k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa1ca802baa544208c121c7fd0b5e019",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/458k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "897129bb300c419e8c896d528ff0f8cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.27M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n"
          ]
        }
      ],
      "source": [
        "from transformers import OpenAIGPTTokenizer\n",
        "\n",
        "tokenizer = OpenAIGPTTokenizer.from_pretrained(\"openai-gpt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juO1TtYkZOTY"
      },
      "source": [
        "Now let's use the tokenizer to tokenize and encode the prompt text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GzgzO0lZH7E",
        "outputId": "9f72029e-5776-43a7-e107-a9429e2e7c38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [3570, 510], 'attention_mask': [1, 1]}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer(\"hello me\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdKXImSdZZt_",
        "outputId": "db4cdccd-c925-42fa-89e8-3173a4b8f22d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 13), dtype=int32, numpy=\n",
              "array([[  616,  5751,  6404,   498,  9606,   240, 10595,   485,   874,\n",
              "          507,   481,  1424,   618]], dtype=int32)>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt_text = \"This royal throne of kings, belongs to Adit the great king\"\n",
        "encoded_prompt = tokenizer.encode(prompt_text,\n",
        "                                  add_special_tokens=False,\n",
        "                                  return_tensors=\"tf\")\n",
        "encoded_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OC5VlW6PaLkS",
        "outputId": "0fa90abf-ecee-476f-d9f9-54c3aa328adb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 53), dtype=int32, numpy=\n",
              "array([[  616,  5751,  6404,   498,  9606,   240, 10595,   485,   874,\n",
              "          507,   481,  1424,   618,   240,   488,   589,   509,  1964,\n",
              "          239, 40477,   244,   481,  4313,   812,  2158,   669,   249,\n",
              "        15791,   575,   240,   244,   547,  3160,  1768,   557,   524,\n",
              "          741,  6869,   485,   510,   239, 40477,   249,  2430,   674,\n",
              "          525,   249,  1388,   485,   727,   246,  1578,   498],\n",
              "       [  616,  5751,  6404,   498,  9606,   240, 10595,   485,   874,\n",
              "          507,   481,  1424,   618,   505,  3983,  2740,   260,   481,\n",
              "         3402,   566,   239, 40477,     7,  1537,   558,   868,   694,\n",
              "         2520,   485, 10647,   240,   568,  1036,   500,   525,  4773,\n",
              "          509,   595,  1046,   239,   524,   945,   240,   499,  6331,\n",
              "          500,   509,   655,  1644,   562,   575,   239,   616],\n",
              "       [  616,  5751,  6404,   498,  9606,   240, 10595,   485,   874,\n",
              "          507,   481,  1424,   618,   240,   618,  8065, 12949,   240,\n",
              "          488,   618,  7479,  8593,   240,   664,  1101,   240,   525,\n",
              "           25,  9272,   268, 19428,  3012,   544, 10812,   666,   867,\n",
              "        16400,   271,   481,   870,   488,   481,  3402,   566,   239,\n",
              "          481, 20297,  4814,  6175,   485,   481,  3970,   504],\n",
              "       [  616,  5751,  6404,   498,  9606,   240, 10595,   485,   874,\n",
              "          507,   481,  1424,   618,  8011,  7791,   498, 16884,   240,\n",
              "          597,  1469,   239,   244, 40477,   491,   616,   481,  5040,\n",
              "        21966,   899,   485,   890,   491, 28445,   240,   763,   626,\n",
              "          538,  2153,   485,  2905,   239,  1596,   487,   816,   609,\n",
              "          488,  1348,   239, 40477,   244,   895,   587,   538],\n",
              "       [  616,  5751,  6404,   498,  9606,   240, 10595,   485,   874,\n",
              "          507,   481,  1424,   618,  1234,   524,  6404,   509,  5115,\n",
              "          500,   481, 35716,  6283,   702,   246, 13002,   240, 24154,\n",
              "          240, 28920,   239,   244, 40477,   481,   762,   509,  2472,\n",
              "          562,   246,   928,  1000,   239, 11264,   816,   714,   491,\n",
              "          481,  1155,   488,   942,   246,  3274,   498, 11402]],\n",
              "      dtype=int32)>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_sequences = 5\n",
        "length = 40\n",
        "\n",
        "generated_sequences = model.generate(\n",
        "    input_ids=encoded_prompt,\n",
        "    do_sample=True,\n",
        "    max_length=length + len(encoded_prompt[0]),\n",
        "    temperature=1.0,\n",
        "    top_k=0,\n",
        "    top_p=0.9,\n",
        "    repetition_penalty=1.0,\n",
        "    num_return_sequences=num_sequences,\n",
        ")\n",
        "\n",
        "generated_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOHGz_mIb-hP"
      },
      "source": [
        "Now let's decode the generated sequences and print them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAjdoIk1by1k",
        "outputId": "9288aa0d-0471-4d94-fa43-76f062467207"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "this royal throne of kings, belongs to adit the great king, and all was free. \n",
            " \" the beast will break when i seize him, \" my uncle whispered as his eyes clung to me. \n",
            " i remembered then that i needed to get a hold of\n",
            "--------------------------------------------------------------------------------\n",
            "this royal throne of kings, belongs to adit the great king eldallan - the evil one. \n",
            " otor had never been forced to flee, but being in that temple was not enough. his son, orthain was there waiting for him. this\n",
            "--------------------------------------------------------------------------------\n",
            "this royal throne of kings, belongs to adit the great king, king hammoth, and king kayria, no less, that cthrag yaska is divided into two kingdoms : the good and the evil one. the badlands belong to the giant on\n",
            "--------------------------------------------------------------------------------\n",
            "this royal throne of kings, belongs to adit the great king korram of oman, now dead. \" \n",
            " at this the remaining representatives turned to look at eben, who didn't seem to notice. suddenly he looked up and smiled. \n",
            " \" why don't\n",
            "--------------------------------------------------------------------------------\n",
            "this royal throne of kings, belongs to adit the great king since his throne was destroyed in the 6th century by a ruthless, soulless, necromancer. \" \n",
            " the man was silent for a long while. colton looked down at the table and felt a wave of nausea\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for sequence in generated_sequences:\n",
        "    text = tokenizer.decode(sequence, clean_up_tokenization_spaces=True)\n",
        "    print(text)\n",
        "    print(\"-\"* 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MF3zIPVLdBM9"
      },
      "source": [
        "You can try more recent (and larger) models, such as GPT-2, CTRL, Transformer-XL or XLNet, which are all available as pretrained models in the transformers library, including variants with Language Models on top. The preprocessing steps vary slightly between models, so make sure to check out this generation example from the transformers documentation (this example uses PyTorch, but it will work with very little tweaks, such as adding TF at the beginning of the model class name, removing the .to() method calls, and using return_tensors=\"tf\" instead of \"pt\".\n",
        "\n",
        "Hope you enjoyed this chapter! :)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "1iSWQLVkcpnN",
        "cevx2zArcpnX"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04363da2c644495fa19ccdad1ecc648a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "05fc2b0a802e4e88946d3a7eb45d0607": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2ca3c6f144d48e49fb6d225aeb1fa62",
            "placeholder": "​",
            "style": "IPY_MODEL_113c339546c14dcaaaaa2ea2946f60e3",
            "value": "tokenizer.json: 100%"
          }
        },
        "06366a00c73f4907bcea01b6206d923a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "063a0557e7ce431f8e94bd19289ccf75": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08d13b02696944e4bd931448db6fe4a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08e08406ec694e158255350e115660ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3df2339cdee4667b662f943f4009500",
            "max": 478736214,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46b37369cdf544a3bebbc2b3ecb7f4fd",
            "value": 478736214
          }
        },
        "113c339546c14dcaaaaa2ea2946f60e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15603e73f1394e658e93e7a9ba519aca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ac71c54dfb84c269b241c0be220f3c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2be12563a7ff49f1ae0b3254faf383b1",
            "max": 656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_04363da2c644495fa19ccdad1ecc648a",
            "value": 656
          }
        },
        "1dec3d2c90b6415b86dde608f1c64a0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e1ebe89c1de4ac98885c7da6bbf447e",
            "placeholder": "​",
            "style": "IPY_MODEL_5cf768c45600400bb2986b88bb8d7a45",
            "value": "config.json: 100%"
          }
        },
        "1f78001e88274b6094a55ab5cbaf18bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08d13b02696944e4bd931448db6fe4a8",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_84221077b1834020bac468b0319b48af",
            "value": 25
          }
        },
        "23d931e144464016b113afdab954c762": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15603e73f1394e658e93e7a9ba519aca",
            "placeholder": "​",
            "style": "IPY_MODEL_b6371f1b7ca948eb9005c2217326069c",
            "value": " 25.0/25.0 [00:00&lt;00:00, 981B/s]"
          }
        },
        "243addd7aeef4d059943db1adb76094e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2be12563a7ff49f1ae0b3254faf383b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3007749421004bcbb7cccac799acbb30": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "399820251d71491dad82a6c327f2d235": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df6dcba2d75d4673be0f7fef28281ead",
              "IPY_MODEL_63de6a75af7f4e92a1266f0ae9b60307",
              "IPY_MODEL_67430626511144cc8842ee799fccb486"
            ],
            "layout": "IPY_MODEL_725105d85216425f9396daaab21524d1"
          }
        },
        "45c70ab7a251408083d3a357d2fb4cca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46b37369cdf544a3bebbc2b3ecb7f4fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "577589a2c1344c009505cb1e6ed85192": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cf768c45600400bb2986b88bb8d7a45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60403cd0e9d24e29b652f035f7f411d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac52321eda81487a82bcde0c698f2267",
            "placeholder": "​",
            "style": "IPY_MODEL_96bc7f56a2a9430ba5250da09bb3ce4b",
            "value": "model.safetensors: 100%"
          }
        },
        "63de6a75af7f4e92a1266f0ae9b60307": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2836f92050e477ba45c3a984879093e",
            "max": 815973,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83666078d0d84aa4af8aabca17403722",
            "value": 815973
          }
        },
        "67430626511144cc8842ee799fccb486": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccce58d4096742bb9375c30ecd18dce2",
            "placeholder": "​",
            "style": "IPY_MODEL_6858d26e35564029a0d8e5d23c221ee3",
            "value": " 816k/816k [00:00&lt;00:00, 3.83MB/s]"
          }
        },
        "6856faa9e01f4f338e8337d8acf36af4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6858d26e35564029a0d8e5d23c221ee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69e22e219d204c14aeb1819d5e685087": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e1ebe89c1de4ac98885c7da6bbf447e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70e70b06a2b64eed9db33e6522bfc892": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "725105d85216425f9396daaab21524d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "775ba2861b3c438a81d9fc22e727f5ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b4a0f19b69d487e84201bdb873fd70f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c89ce4b91054c878bdae74e690c68f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ffd99a522f146bfb7a59b5e20044bd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_775ba2861b3c438a81d9fc22e727f5ae",
            "placeholder": "​",
            "style": "IPY_MODEL_967c6f8ee0984d7c9289f8e6af1a27b3",
            "value": " 458k/458k [00:00&lt;00:00, 15.6MB/s]"
          }
        },
        "82733b6c252a4f7682c06b92818c06f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_60403cd0e9d24e29b652f035f7f411d1",
              "IPY_MODEL_08e08406ec694e158255350e115660ea",
              "IPY_MODEL_8f604590bca0467e95dedfabdddc9217"
            ],
            "layout": "IPY_MODEL_577589a2c1344c009505cb1e6ed85192"
          }
        },
        "8344db2b95df40868d4ad5f93876a042": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83666078d0d84aa4af8aabca17403722": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84221077b1834020bac468b0319b48af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84919481c9214616b01b15ba955a72dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3007749421004bcbb7cccac799acbb30",
            "max": 1272610,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96bf2cfc2ab74d30aeee7ccc739ab9c1",
            "value": 1272610
          }
        },
        "897129bb300c419e8c896d528ff0f8cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05fc2b0a802e4e88946d3a7eb45d0607",
              "IPY_MODEL_84919481c9214616b01b15ba955a72dd",
              "IPY_MODEL_a2b15a0c56234745a39b4c0a1aa5e8b8"
            ],
            "layout": "IPY_MODEL_b8133c451d1f4d319b4c4b79af16b000"
          }
        },
        "8c40845e997b4b4281279e3befdd796b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f604590bca0467e95dedfabdddc9217": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c40845e997b4b4281279e3befdd796b",
            "placeholder": "​",
            "style": "IPY_MODEL_95da085a0ce1488d8dbc86a982765001",
            "value": " 479M/479M [00:05&lt;00:00, 82.4MB/s]"
          }
        },
        "945b5ce3f3b44cc0a06b61501cdc0616": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95da085a0ce1488d8dbc86a982765001": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "967c6f8ee0984d7c9289f8e6af1a27b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96bc7f56a2a9430ba5250da09bb3ce4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96bf2cfc2ab74d30aeee7ccc739ab9c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2836f92050e477ba45c3a984879093e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2b15a0c56234745a39b4c0a1aa5e8b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_243addd7aeef4d059943db1adb76094e",
            "placeholder": "​",
            "style": "IPY_MODEL_945b5ce3f3b44cc0a06b61501cdc0616",
            "value": " 1.27M/1.27M [00:00&lt;00:00, 5.62MB/s]"
          }
        },
        "ac52321eda81487a82bcde0c698f2267": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3df2339cdee4667b662f943f4009500": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6371f1b7ca948eb9005c2217326069c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8133c451d1f4d319b4c4b79af16b000": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb34946d8176431b872876a898fa7f15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70e70b06a2b64eed9db33e6522bfc892",
            "placeholder": "​",
            "style": "IPY_MODEL_45c70ab7a251408083d3a357d2fb4cca",
            "value": " 656/656 [00:00&lt;00:00, 31.9kB/s]"
          }
        },
        "bf2228f3cf4443469bee101f6637a27b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c18f6ea268644b47a376f240c25bde7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9853dafcbca4d54854c683313bab9fb",
            "placeholder": "​",
            "style": "IPY_MODEL_6856faa9e01f4f338e8337d8acf36af4",
            "value": "merges.txt: 100%"
          }
        },
        "ccce58d4096742bb9375c30ecd18dce2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf9b0f4ad2e64396974b254ae072c045": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff6388e7208943ef814edae516394dcf",
              "IPY_MODEL_1f78001e88274b6094a55ab5cbaf18bf",
              "IPY_MODEL_23d931e144464016b113afdab954c762"
            ],
            "layout": "IPY_MODEL_8344db2b95df40868d4ad5f93876a042"
          }
        },
        "d9853dafcbca4d54854c683313bab9fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df6dcba2d75d4673be0f7fef28281ead": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf2228f3cf4443469bee101f6637a27b",
            "placeholder": "​",
            "style": "IPY_MODEL_06366a00c73f4907bcea01b6206d923a",
            "value": "vocab.json: 100%"
          }
        },
        "e6e36a23c0c64576ba789ece88971c39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1dec3d2c90b6415b86dde608f1c64a0e",
              "IPY_MODEL_1ac71c54dfb84c269b241c0be220f3c9",
              "IPY_MODEL_bb34946d8176431b872876a898fa7f15"
            ],
            "layout": "IPY_MODEL_063a0557e7ce431f8e94bd19289ccf75"
          }
        },
        "e990c3368b0e4657b94e60649c13709b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f146dd3aff204c3d982471f83e596adb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2ca3c6f144d48e49fb6d225aeb1fa62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f35a55a913a34f8283b0a13a614825f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e990c3368b0e4657b94e60649c13709b",
            "max": 458495,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69e22e219d204c14aeb1819d5e685087",
            "value": 458495
          }
        },
        "fa1ca802baa544208c121c7fd0b5e019": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c18f6ea268644b47a376f240c25bde7d",
              "IPY_MODEL_f35a55a913a34f8283b0a13a614825f7",
              "IPY_MODEL_7ffd99a522f146bfb7a59b5e20044bd1"
            ],
            "layout": "IPY_MODEL_7b4a0f19b69d487e84201bdb873fd70f"
          }
        },
        "ff6388e7208943ef814edae516394dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f146dd3aff204c3d982471f83e596adb",
            "placeholder": "​",
            "style": "IPY_MODEL_7c89ce4b91054c878bdae74e690c68f8",
            "value": "tokenizer_config.json: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
